{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Importing all libraries\n",
                "import pandas as pd\n",
                "from matplotlib import pyplot as plt\n",
                "import numpy as np \n",
                "%matplotlib inline\n",
                "\n",
                "from sklearn.gaussian_process import GaussianProcessRegressor\n",
                "from sklearn.gaussian_process.kernels import RBF\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.gaussian_process.kernels import RationalQuadratic, ConstantKernel as C\n",
                "from sklearn.preprocessing import StandardScaler\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Preparing training sets"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "clean_data = pd.read_csv('clean_data_final.csv')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0      2023-11-06 02:10:21\n",
                            "1      2023-11-06 02:30:14\n",
                            "2      2023-11-06 02:50:08\n",
                            "3      2023-11-06 03:11:00\n",
                            "4      2023-11-06 03:30:55\n",
                            "              ...         \n",
                            "453    2023-11-07 10:40:01\n",
                            "454    2023-11-07 11:42:25\n",
                            "455    2023-11-07 12:05:30\n",
                            "456    2023-11-07 12:20:37\n",
                            "457    2023-11-07 12:36:21\n",
                            "Name: Time, Length: 458, dtype: object"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "clean_data['Time']\n",
                "\n",
                "#The data in this csv file has already been transformed to a more workable formatting under\n",
                "#certain assumptions:\n",
                "    #1) Assumed that the scraper collection begain on Monday, Nov 6th, and ended the Tuesday next week, Nov 14th.\n",
                "\n",
                "    #2) Considering this, there are two sets of data for Monday and Tuesday as data for their trends have \n",
                "    #been recorded twice (Nov 6th, Nov 7th, and again on Nov 13th, Nov 14th)\n",
                "    #Therefore: Assumed that the trends across these pairs of Mondays and Tuesdays are similar enough\n",
                "    #to be considered the same day, and changed the dates in the csv file accordingly. \n",
                "        #So, there's no date for Nov 13th nor the 14th on the csv, but rather their scraped data was simply\n",
                "        #added to Nov 6th and the 7th. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0     2023-11-06 02:10:21\n",
                            "1     2023-11-06 02:30:14\n",
                            "2     2023-11-06 02:50:08\n",
                            "3     2023-11-06 03:11:00\n",
                            "4     2023-11-06 03:30:55\n",
                            "              ...        \n",
                            "453   2023-11-07 10:40:01\n",
                            "454   2023-11-07 11:42:25\n",
                            "455   2023-11-07 12:05:30\n",
                            "456   2023-11-07 12:20:37\n",
                            "457   2023-11-07 12:36:21\n",
                            "Name: Time_obj, Length: 458, dtype: datetime64[ns]"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Converting csv file dataframe to a pandas datetime object\n",
                "\n",
                "clean_data['Time_obj'] = pd.to_datetime(clean_data['Time'], errors = 'raise')\n",
                "clean_data['Time_obj']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([ 6,  7,  8,  9, 10, 11, 12], dtype=int32)"
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#using the 'day' attritube to extract the day from the date\n",
                "clean_data['day'] = clean_data['Time_obj'].dt.day\n",
                "clean_data['day'].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([0, 1, 2, 3, 4, 5, 6], dtype=int32)"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Changing days to a transformable form:\n",
                "#preparation for conversion from days -> hours\n",
                "\n",
                "#To write days in terms of hours, one would simply be to multiply the day by 24.\n",
                "#But what we currently have are days of the month, ex. the 6th, the 9th, the 12th, etc. So multiplying\n",
                "#these numbers by 24 to convert them to hours is faulty logic. \n",
                "\n",
                "#Instead, we can first convert these dates to number them by their day of the week, \n",
                "#starting with day 0 and ending with day 6 for a total of 7 days.\n",
                "\n",
                "#Once that's done, we can multiply those numbers (0-6) to accurately calculate the days in terms of hours,\n",
                "#where 1 week is 168 hours long.\n",
                "\n",
                "#Here, Monday will be the 0th day of the week since that's when the scraper is assumed to start working,\n",
                "#So 12:00 AM on a Monday is considered hour 0 of day 0. 12:00 PM on Monday is considered the 12th hour\n",
                "#of the whole week, 12:00 AM on Tuesday is considered the 24th hour of the week, so on and so forth.\n",
                "\n",
                "#If anyone's got any better ideas than this, feel free to try them out since this is probably\n",
                "#an overcomplicated solution\n",
                "\n",
                "#-----------------------------------------------------------------------------------------------------------\n",
                "\n",
                "replacing = True            #used to start while loop for changing the days dataframe\n",
                "counter = 0                 #Beginning at Monday, here considered the 0th day of the week with 12 AM being the 0th hour\n",
                "day = 6                     #The data is assumed to start on the 6th of November, so the day counter will start on that date\n",
                "\n",
                "while(replacing):                                                               #Replaces the corresponding day from the raw data to a workable default day (Monday the 6th = day 0, Tuesday the 7th = day 1, etc)\n",
                "    clean_data['day'] = clean_data['day'].replace(day, counter)                 #Replaces all numbers that match the day variable with the value of the counter\n",
                "    day += 1\n",
                "    counter += 1                                                                #Once all numbers are replaced for the current day, increment day and counter to move on and replace the values for the next day\n",
                "\n",
                "    if (counter == 7):\n",
                "        replacing = False\n",
                "\n",
                "clean_data['day'].unique() #Viola"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array([  0,  24,  48,  72,  96, 120, 144], dtype=int32)"
                        ]
                    },
                    "execution_count": 7,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Converting from days to hours\n",
                "clean_data['days_as_hours'] = clean_data['day'] * 24\n",
                "clean_data['days_as_hours'].unique()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0       2.166667\n",
                            "1       2.500000\n",
                            "2       2.833333\n",
                            "3       3.183333\n",
                            "4       3.500000\n",
                            "         ...    \n",
                            "453    34.666667\n",
                            "454    35.700000\n",
                            "455    36.083333\n",
                            "456    36.333333\n",
                            "457    36.600000\n",
                            "Name: Final_time, Length: 458, dtype: float64"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Preparing final time by writing time as days, hours, and minutes in terms of hours\n",
                "#Preparing minutes and hours, then adding to days\n",
                "\n",
                "#Retrievting minutes\n",
                "clean_data['mins'] = clean_data['Time_obj'].dt.minute\n",
                "\n",
                "#Retrievting hours\n",
                "clean_data['hrs'] = clean_data['Time_obj'].dt.hour\n",
                "\n",
                "#Writing minutes in terms of hours\n",
                "clean_data['mins_as_hrs'] = clean_data['mins'].divide(60.0)\n",
                "\n",
                "#Adding the arrays to calculate the final time\n",
                "clean_data['hrs_and_mins'] = clean_data['hrs'].add(clean_data['mins_as_hrs'])\n",
                "clean_data['Final_time'] = clean_data['hrs_and_mins'].add(clean_data['days_as_hours'])\n",
                "\n",
                "#double checking shape and formatting\n",
                "clean_data['Final_time']"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(458, 1)"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Initialize training set, X axis\n",
                "Time_scraped = np.array(clean_data['Final_time'])\n",
                "Time_scraped = Time_scraped.reshape(-1, 1)\n",
                "\n",
                "Time_scraped.shape"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Initializing training sets, Y axis\n",
                "\n",
                "#Pg1\n",
                "y_pg1 = np.array(clean_data['PG1'])\n",
                "y_pg1 = y_pg1.reshape(-1, 1)\n",
                "\n",
                "#Pg2\n",
                "y_pg2 = np.array(clean_data['PG2'])\n",
                "y_pg2 = y_pg2.reshape(-1, 1)\n",
                "\n",
                "#Pg3\n",
                "y_pg3 = np.array(clean_data['PG3'])\n",
                "y_pg3 = y_pg3.reshape(-1, 1)\n",
                "\n",
                "#Pg4\n",
                "y_pg4 = np.array(clean_data['PG4'])\n",
                "y_pg4 = y_pg4.reshape(-1, 1)\n",
                "\n",
                "#Pg5\n",
                "y_pg5 = np.array(clean_data['PG5'])\n",
                "y_pg5 = y_pg5.reshape(-1, 1)\n",
                "\n",
                "#Pg6\n",
                "y_pg6 = np.array(clean_data['PG6'])\n",
                "y_pg6 = y_pg6.reshape(-1, 1)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Prompting User Input"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Calculating empty spaces for each garage at 13:00 on Monday.\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "array([[13.]])"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Requesting user input \n",
                "time_request = input(\"Enter a time in 00:00 24-hour time formatting: \")\n",
                "day_request = input(\"Enter the day of the week (Monday, Tuesday, etc.): \")\n",
                "print(\"Calculating empty spaces for each garage at \" + time_request + \" on \" + day_request + \".\")\n",
                "\n",
                "time_request = pd.to_datetime(time_request, errors = 'raise')\n",
                "\n",
                "#Changes String days to numbered version of the days of the week\n",
                "match day_request:\n",
                "    case \"Monday\":\n",
                "        day_request = 0\n",
                "    case \"Tuesday\":\n",
                "        day_request = 1\n",
                "    case \"Wednesday\":\n",
                "        day_request = 2\n",
                "    case \"Thursday\":\n",
                "        day_request = 3\n",
                "    case \"Friday\":\n",
                "        day_request = 4\n",
                "    case \"Saturday\":\n",
                "        day_request = 5\n",
                "    case \"Sunday\":\n",
                "        day_request = 6\n",
                "\n",
                "request = (day_request * 24) + time_request.hour + (time_request.minute / 60)\n",
                "\n",
                "#Predictions need to be passed through as an array, so let's place this into one and reshape it\n",
                "request_df = pd.DataFrame(request, index = [0], columns = ['Request'])\n",
                "final_request = np.array(request_df).reshape(-1, 1)\n",
                "\n",
                "final_request"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "1.1**2 * RationalQuadratic(alpha=0.159, length_scale=6.06) * 0.898**2 * RBF(length_scale=6.76)"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#PG1 Model\n",
                "#Initialize the GPR\n",
                "from sklearn.gaussian_process.kernels import ExpSineSquared\n",
                "\n",
                "#Initializing kernels\n",
                "noise_kernel_pg1 = C(1.0, (1e-3, 1e3)) * RationalQuadratic(length_scale = 1.0, alpha = 1.0, length_scale_bounds = (1e-5, 1e5), alpha_bounds = (1e-10, 1e10))\n",
                "rbf_pg1 = 1.0**1 * RBF(length_scale = 1.0, length_scale_bounds = (1e-2, 1e2))\n",
                "\n",
                "#linear_kernel_pg1 = C(1.0, (1e-3, 1e3))\n",
                "\n",
                "#exp_kernel_pg1 = ExpSineSquared() #* RBF(length_scale = 100.0, length_scale_bounds = (1e-2, 1e2))\n",
                "\n",
                "\n",
                "#Combined kernel_pg1\n",
                "kernel_pg1 = (noise_kernel_pg1 * rbf_pg1)\n",
                "\n",
                "#Initialize GaussianProcessRegressor and fit\n",
                "gaussian_process_pg1 = GaussianProcessRegressor(kernel = kernel_pg1, alpha = 0.1, n_restarts_optimizer = 10, normalize_y=True)\n",
                "#Alpha of kernel -> standard deviation\n",
                "\n",
                "gaussian_process_pg1.fit(Time_scraped, y_pg1)\n",
                "gaussian_process_pg1.kernel_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Pg1 Prediction \n",
                "mean_prediction_pg1, std_prediction_pg1 = gaussian_process_pg1.predict(final_request, return_std = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0.677**2 * RBF(length_scale=3.57) + 0.699**2 * RationalQuadratic(alpha=1e+05, length_scale=43.2)"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Pg2 Model\n",
                "\n",
                "#Kernels\n",
                "noise_kernel_pg2 = C(1.0, (1e-3, 1e3)) * RationalQuadratic(length_scale = 1.0, alpha = 1.0)\n",
                "rbf_pg2 = 1.0**1 * RBF(length_scale = 1.0, length_scale_bounds = (1e-2, 1e2))\n",
                "\n",
                "kernel_pg2 = (rbf_pg2 + noise_kernel_pg2)\n",
                "\n",
                "#Initialize GaussianProcessRegressor and fit\n",
                "gaussian_process_pg2 = GaussianProcessRegressor(kernel = kernel_pg2, alpha = 0.1, n_restarts_optimizer = 10, normalize_y=True)\n",
                "\n",
                "gaussian_process_pg2.fit(Time_scraped, y_pg2)\n",
                "gaussian_process_pg2.kernel_\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Pg2 Prediction\n",
                "mean_prediction_pg2, std_prediction_pg2 = gaussian_process_pg2.predict(final_request, return_std = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.11/site-packages/sklearn/gaussian_process/kernels.py:429: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
                        "  warnings.warn(\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0.464**2 * RBF(length_scale=2.54) + 0.877**2 * RationalQuadratic(alpha=1e+05, length_scale=5.95)"
                        ]
                    },
                    "execution_count": 16,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Pg3 Model \n",
                "\n",
                "#Kernels\n",
                "noise_kernel_pg3 = C(1.0, (1e-3, 1e3)) * RationalQuadratic(length_scale = 1.0, alpha = 1.0)\n",
                "rbf_pg3 = 1.0**1 * RBF(length_scale = 1.0, length_scale_bounds = (1e-2, 1e2))\n",
                "\n",
                "kernel_pg3 = (rbf_pg3 + noise_kernel_pg3)\n",
                "\n",
                "#Initialize GaussianProcessRegressor and fit\n",
                "gaussian_process_pg3 = GaussianProcessRegressor(kernel = kernel_pg3, alpha = 0.1, n_restarts_optimizer = 10, normalize_y=True)\n",
                "\n",
                "gaussian_process_pg3.fit(Time_scraped, y_pg3)\n",
                "gaussian_process_pg3.kernel_\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Pg3 Prediction\n",
                "mean_prediction_pg3, std_prediction_pg3 = gaussian_process_pg3.predict(final_request, return_std = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.89**2 * RBF(length_scale=4.7) + 0.356**2 * RationalQuadratic(alpha=1.35e+07, length_scale=2.61)"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Pg4 Model\n",
                "\n",
                "#Kernels\n",
                "noise_kernel_pg4 = C(1.0, (1e-3, 1e3)) * RationalQuadratic(length_scale = 1.0, alpha = 1.0, alpha_bounds = (1e-10, 1e10))\n",
                "rbf_pg4 = 1.0**1 * RBF(length_scale = 1.0, length_scale_bounds = (1e-2, 1e2))\n",
                "\n",
                "kernel_pg4 = (rbf_pg4 + noise_kernel_pg4)\n",
                "\n",
                "#Initialize GaussianProcessRegressor and fit\n",
                "gaussian_process_pg4 = GaussianProcessRegressor(kernel = kernel_pg4, alpha = 0.1, n_restarts_optimizer = 10, normalize_y=True)\n",
                "\n",
                "gaussian_process_pg4.fit(Time_scraped, y_pg4)\n",
                "gaussian_process_pg4.kernel_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "#pg4 prediction\n",
                "mean_prediction_pg4, std_prediction_pg4 = gaussian_process_pg4.predict(final_request, return_std = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.872**2 * RBF(length_scale=3.59) + 0.362**2 * RationalQuadratic(alpha=1.17e+03, length_scale=43.2)"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Pg5 Model \n",
                "\n",
                "#Kernels\n",
                "noise_kernel_pg5 = C(1.0, (1e-3, 1e3)) * RationalQuadratic(length_scale = 1.0, alpha = 1.0)\n",
                "rbf_pg5 = 1.0**1 * RBF(length_scale = 1.0, length_scale_bounds = (1e-2, 1e2))\n",
                "\n",
                "kernel_pg5 = (rbf_pg5 + noise_kernel_pg5)\n",
                "\n",
                "#Initialize GaussianProcessRegressor and fit\n",
                "gaussian_process_pg5 = GaussianProcessRegressor(kernel = kernel_pg5, alpha = 0.1, n_restarts_optimizer = 10, normalize_y=True)\n",
                "\n",
                "gaussian_process_pg5.fit(Time_scraped, y_pg5)\n",
                "gaussian_process_pg5.kernel_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "#pg5 prediction\n",
                "mean_prediction_pg5, std_prediction_pg5 = gaussian_process_pg5.predict(final_request, return_std = True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/usr/local/lib/python3.11/site-packages/sklearn/gaussian_process/_gpr.py:663: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
                        "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
                        "\n",
                        "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
                        "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
                        "  _check_optimize_result(\"lbfgs\", opt_res)\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "0.876**2 * RBF(length_scale=4.75) + 0.353**2 * RationalQuadratic(alpha=1.96e+07, length_scale=2.39)"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#Pg6 Model\n",
                "\n",
                "#Kernels\n",
                "noise_kernel_pg6 = C(1.0, (1e-3, 1e3)) * RationalQuadratic(length_scale = 1.0, alpha = 1.0, alpha_bounds = (1e-10, 1e10))\n",
                "rbf_pg6 = 1.0**1 * RBF(length_scale = 1.0, length_scale_bounds = (1e-2, 1e2))\n",
                "\n",
                "kernel_pg6 = (rbf_pg6 + noise_kernel_pg6)\n",
                "\n",
                "#Initialize GaussianProcessRegressor and fit\n",
                "gaussian_process_pg6 = GaussianProcessRegressor(kernel = kernel_pg6, alpha = 0.1, n_restarts_optimizer = 5, normalize_y=True)\n",
                "\n",
                "gaussian_process_pg6.fit(Time_scraped, y_pg6)\n",
                "gaussian_process_pg6.kernel_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Pg6 Prediction\n",
                "mean_prediction_pg6, std_prediction_pg6 = gaussian_process_pg6.predict(final_request, return_std = True)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Collecting and Exporting Predictions as Csv"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [],
            "source": [
                "#Collect Predictions into one dataframe and use .T (transpose) to flip the column to a row\n",
                "predictions_collection = pd.DataFrame([mean_prediction_pg1, mean_prediction_pg2, mean_prediction_pg3, mean_prediction_pg4, mean_prediction_pg5, mean_prediction_pg6]).T\n",
                "\n",
                "#add column names\n",
                "predictions_collection.columns = ['PG1_Values', 'PG2_Values', 'PG3_Values', 'PG4_Values', 'PG5_Values', 'PG6_Values']\n",
                "\n",
                "#export to csv\n",
                "predictions_collection.to_csv('predictions.csv')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
